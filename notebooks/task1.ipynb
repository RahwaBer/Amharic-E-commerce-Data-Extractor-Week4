{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c3ce885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total channels available: 22\n",
      "\n",
      "1. @ZemenExpress\n",
      "2. @nevacomputer\n",
      "3. @meneshayeofficial\n",
      "4. @ethio_brand_collection\n",
      "5. @Leyueqa\n",
      "6. @sinayelj\n",
      "7. @Shewabrand\n",
      "8. @helloomarketethiopia\n",
      "9. @modernshoppingcenter\n",
      "10. @qnashcom\n",
      "11. @Fashiontera\n",
      "12. @kuruwear\n",
      "13. @gebeyaadama\n",
      "14. @MerttEka\n",
      "15. @forfreemarket\n",
      "16. @classybrands\n",
      "17. @marakibrand\n",
      "18. @aradabrand2\n",
      "19. @marakisat2\n",
      "20. @belaclassic\n",
      "21. @AwasMart\n",
      "22. @qnashcom\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "channels_df = pd.read_excel(r\"channels_to_crawl.xlsx\")\n",
    "\n",
    "print(f\"Total channels available: {len(channels_df)}\\n\")\n",
    "\n",
    "# Display the first 10 as a sample for manual selection\n",
    "for idx, name in enumerate(channels_df.iloc[:, 0].tolist(), start=1):\n",
    "    print(f\"{idx}. {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97e2bedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from telethon import TelegramClient\n",
    "import csv\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables once\n",
    "load_dotenv('.env')\n",
    "api_id = os.getenv('TG_API_ID')\n",
    "api_hash = os.getenv('TG_API_HASH')\n",
    "phone = os.getenv('phone')\n",
    "\n",
    "# Function to scrape data from a single channel\n",
    "async def scrape_channel(client, channel_username, writer, media_dir):\n",
    "    entity = await client.get_entity(channel_username)\n",
    "    channel_title = entity.title  # Extract the channel's title\n",
    "    async for message in client.iter_messages(entity, limit=10000):\n",
    "        media_path = None\n",
    "        if message.media and hasattr(message.media, 'photo'):\n",
    "            # Create a unique filename for the photo\n",
    "            filename = f\"{channel_username}_{message.id}.jpg\"\n",
    "            media_path = os.path.join(media_dir, filename)\n",
    "            # Download the media to the specified directory if it's a photo\n",
    "            await client.download_media(message.media, media_path)\n",
    "        \n",
    "        # Write the channel title along with other data\n",
    "        writer.writerow([channel_title, channel_username, message.id, message.message, message.date, media_path])\n",
    "\n",
    "# Initialize the client once\n",
    "client = TelegramClient('scraping_session', api_id, api_hash)\n",
    "\n",
    "async def main():\n",
    "    await client.start()\n",
    "    \n",
    "    # Create a directory for media files\n",
    "    media_dir = 'photos'\n",
    "    os.makedirs(media_dir, exist_ok=True)\n",
    "\n",
    "    # Open the CSV file and prepare the writer\n",
    "    with open('telegram_data.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Channel Title', 'Channel Username', 'ID', 'Message', 'Date', 'Media Path'])  # Include channel title in the header\n",
    "        \n",
    "        # List of channels to scrape\n",
    "        channels = [\n",
    "            '@nevacomputer',\n",
    "            '@meneshayeofficial',\n",
    "            '@ethio_brand_collection',\n",
    "            '@Leyueqa',\n",
    "            '@sinayelj',  \n",
    "\n",
    "        ]\n",
    "        # Iterate over channels and scrape data into the single CSV file\n",
    "        for channel in channels:\n",
    "            await scrape_channel(client, channel, writer, media_dir)\n",
    "            print(f\"Scraped data from {channel}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d38d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "import asyncio\n",
    "\n",
    "nest_asyncio.apply()  \n",
    "\n",
    "async def wrapper():\n",
    "    async with client:\n",
    "        await main()\n",
    "\n",
    "await wrapper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "187a3c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel Title</th>\n",
       "      <th>Channel Username</th>\n",
       "      <th>ID</th>\n",
       "      <th>Message</th>\n",
       "      <th>Date</th>\n",
       "      <th>Media Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEVA COMPUTERÂ®</td>\n",
       "      <td>@nevacomputer</td>\n",
       "      <td>8775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-06-11 13:56:52+00:00</td>\n",
       "      <td>photos\\@nevacomputer_8775.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEVA COMPUTERÂ®</td>\n",
       "      <td>@nevacomputer</td>\n",
       "      <td>8774</td>\n",
       "      <td>LENOVO X1 YOGA\\nProcessor: 11thâ€‘Gen Intel Core...</td>\n",
       "      <td>2025-06-11 13:56:52+00:00</td>\n",
       "      <td>photos\\@nevacomputer_8774.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NEVA COMPUTERÂ®</td>\n",
       "      <td>@nevacomputer</td>\n",
       "      <td>8773</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-06-11 13:56:52+00:00</td>\n",
       "      <td>photos\\@nevacomputer_8773.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEVA COMPUTERÂ®</td>\n",
       "      <td>@nevacomputer</td>\n",
       "      <td>8772</td>\n",
       "      <td>ðŸ”¥ Acer Nitro 5 â€“ Power Meets Performance\\n\\nðŸ’» ...</td>\n",
       "      <td>2025-06-09 21:37:09+00:00</td>\n",
       "      <td>photos\\@nevacomputer_8772.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEVA COMPUTERÂ®</td>\n",
       "      <td>@nevacomputer</td>\n",
       "      <td>8771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-06-09 21:37:09+00:00</td>\n",
       "      <td>photos\\@nevacomputer_8771.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Channel Title Channel Username    ID  \\\n",
       "0  NEVA COMPUTERÂ®    @nevacomputer  8775   \n",
       "1  NEVA COMPUTERÂ®    @nevacomputer  8774   \n",
       "2  NEVA COMPUTERÂ®    @nevacomputer  8773   \n",
       "3  NEVA COMPUTERÂ®    @nevacomputer  8772   \n",
       "4  NEVA COMPUTERÂ®    @nevacomputer  8771   \n",
       "\n",
       "                                             Message  \\\n",
       "0                                                NaN   \n",
       "1  LENOVO X1 YOGA\\nProcessor: 11thâ€‘Gen Intel Core...   \n",
       "2                                                NaN   \n",
       "3  ðŸ”¥ Acer Nitro 5 â€“ Power Meets Performance\\n\\nðŸ’» ...   \n",
       "4                                                NaN   \n",
       "\n",
       "                        Date                     Media Path  \n",
       "0  2025-06-11 13:56:52+00:00  photos\\@nevacomputer_8775.jpg  \n",
       "1  2025-06-11 13:56:52+00:00  photos\\@nevacomputer_8774.jpg  \n",
       "2  2025-06-11 13:56:52+00:00  photos\\@nevacomputer_8773.jpg  \n",
       "3  2025-06-09 21:37:09+00:00  photos\\@nevacomputer_8772.jpg  \n",
       "4  2025-06-09 21:37:09+00:00  photos\\@nevacomputer_8771.jpg  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"..\\telegram_data.csv\", encoding=\"utf-8\", engine=\"python\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ff441e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Cleaned and tokenized Amharic text saved.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "# Normalize Amharic Text\n",
    "def normalize_amharic(text):\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "    \n",
    "    # Remove emojis, English text, and punctuation\n",
    "    text = re.sub(r'[^\\u1200-\\u137F\\s]+', '', text)\n",
    "\n",
    "    \n",
    "    # Normalize whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Remove diacritics\n",
    "    text = ''.join(c for c in unicodedata.normalize('NFD', text) if unicodedata.category(c) != 'Mn')\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "# Simple Tokenizer (by whitespace)\n",
    "def tokenize_amharic(text):\n",
    "    return text.split()\n",
    "\n",
    "# Apply cleaning\n",
    "df['cleaned_text'] = df['Message'].apply(normalize_amharic)\n",
    "df['tokens'] = df['cleaned_text'].apply(tokenize_amharic)\n",
    "\n",
    "# Save cleaned data\n",
    "df.to_csv(\"../src/messages_cleaned.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Cleaned and tokenized Amharic text saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a2a8b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Structured data saved to: ../src/structured_telegram_data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Load raw message data\n",
    "df = pd.read_csv(\"../src/messages_cleaned.csv\")\n",
    "\n",
    "# ========== NORMALIZATION FUNCTION ==========\n",
    "def normalize_amharic(text):\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "    \n",
    "    # Remove emojis, foreign characters, and punctuation (retain only Ge'ez script and numbers)\n",
    "    text = re.sub(r'[^\\u1200-\\u137F\\u1369-\\u137C0-9\\s]', '', text)\n",
    "    \n",
    "    # Remove diacritics\n",
    "    text = ''.join(c for c in unicodedata.normalize('NFD', text) if unicodedata.category(c) != 'Mn')\n",
    "    \n",
    "    # Normalize whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "# ========== TOKENIZATION FUNCTION ==========\n",
    "def tokenize_amharic(text):\n",
    "    return text.split()\n",
    "\n",
    "# ========== CLEANING AND STRUCTURING ==========\n",
    "df['cleaned_text'] = df['Message'].apply(normalize_amharic)\n",
    "df['tokens'] = df['cleaned_text'].apply(tokenize_amharic)\n",
    "\n",
    "# Select and rename columns\n",
    "final_df = df[['Channel Username', 'Date', 'Media Path', 'cleaned_text', 'tokens']].copy()\n",
    "\n",
    "# Save final structured data\n",
    "output_path = \"../src/structured_telegram_data.csv\"\n",
    "final_df.to_csv(output_path, index=False)\n",
    "print(f\"âœ… Structured data saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4427f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
